# /core – fonctions, mécanismes et flux métier

Ce document décrit de manière approfondie chaque fichier de `/core`, les fonctions qu’il expose, leurs entrées/sorties et les flux de données ou tables qu’elles manipulent. Il complète la carte mentale et te permet de suivre, pour chaque module cœur, la logique du traitement (extraction PDF → factures, gestion des backups, POS, etc.).

## 1. `core/backup_manager.py`
- **Responsabilité** : tout ce qui touche aux sauvegardes PostgreSQL sur disque, depuis la configuration jusqu’à la restauration et les diagnostics.
- **Flux métier** :
  1. Configuration/découverte du dossier `BACKUP_DIR` (`get_backup_directory`, `_settings_path`, `load_backup_settings`, `save_backup_settings`).
  2. Inspection des fichiers (extension `.sql`, `.sql.gz`). Chaque entrée devient un `BackupMetadata` (nom, taille, horodatage) utilisé par `list_backups`, `build_backup_timeline`, `compute_backup_statistics`.
  3. Planification automatique (`plan_next_backup`) qui combine fréquence (daily/weekly/manual), heure et dernier backup connu pour proposer la prochaine exécution.
  4. Création (`create_backup`) : normalisation de `DATABASE_URL`, résolution du binaire `pg_dump`, exécution de la commande, compression gzip, retour d’un métadonnée.
  5. Restauration/détection (`restore_backup`, `delete_backup`, `_resolve_backup_path`, `check_backup_integrity`, `integrity_report`, `suggest_retention_cleanup`) : sécurise l’accès au fichier, vérifie la structure gzip, traite la suppression ou la restauration via `psql`.
  6. Diagnostic des outils (`check_backup_tools`) utilisé par l’interface admin pour afficher si `pg_dump`/`psql` sont disponibles.
- **Tables/fichiers** : aucun, fonctionne uniquement sur le système de fichiers et `database_url`. Néanmoins, il est utilisé en amont des services admin/maintenance pour orchestrer la reprise après un incident.

## 2. `core/cart_normalizer.py`
- **Responsabilité** : homogénéiser les lignes du panier (fonctions PoS/Streamlit) avant traitement.
- **Fonctions clés** :
  1. `_FIELD_ALIASES` : mappe chaque variante de clé (français, camelCase, anglais) vers la nomenclature canonique (`id`, `nom`, `qty`, `prix_vente`, `tva`, `prix_total`).
  2. `_coerce_float` / `_coerce_int` : convertissent/purifient les valeurs numériques, suppriment symboles (€), gèrent les champs vides.
  3. `normalize_cart_rows` : pour chaque ligne, on réalise la canonicalisation, on garantit une quantité >= 0, on recalcule `prix_total`, on fallback sur `Produit {id}` lorsque le nom est absent. Le résultat est prêt à être passé à `inventory_service.process_sale_transaction`.
- **Flux** : session PoS → `normalize_cart_rows` → `process_sale_transaction` → `mouvements_stock` / tickets.

## 3. `core/database_url.py`
- **Responsabilité** : construire un `DATABASE_URL` SQLAlchemy compatible avec l’environnement.
- **Logiciel** : cherche la variable `DATABASE_URL` complète et à défaut compose un identifiant à partir de `POSTGRES_*` ou `DB_*` (user, password, host, port, database) et échappe les paramètres avec `quote_plus`.
- **Impact** : ce helper est utilisé par `data_repository` et par tous les services qui accèdent à la base. Il permet de basculer de l’environnement local (localhost) au Docker/production sans modifier le code métier.

## 4. `core/data_repository.py`
- **Responsabilité** : fournir le moteur SQLAlchemy partagé (pool, configuration) et des helpers pour exécuter des requêtes.
- **Composants** :
  1. `get_engine()` : cache via Streamlit, pool_size 10 + max_overflow 20, `pool_pre_ping` pour éviter les connexions mortes.
  2. `_normalize_statement()` : acceptation d’une chaîne SQL ou d’un `ClauseElement` SQLAlchemy.
  3. `query_df()` : exécution `SELECT`, binding sécurisé, fallback `exec_driver_sql` pour certains drivers, retour `pd.DataFrame` (vide si aucun résultat). Utilisé massivement (catalogue, dashboard, rapports, audit).
  4. `exec_sql()` / `exec_sql_return_id()` : wrappers pour INSERT/UPDATE/DELETE – supportaient aussi les batchs (`params` en liste). Employés par `products_loader`, `price_history_service`, `user_service`.
  5. `get_product_options()` / `get_product_details()` : utilitaires (liste de produits ou lookup par ID/code) destinés à la UI Streamlit mais réutilisables dans d’autres scripts. `get_product_details` joint `produits` et `produits_barcodes`.
- **Flux** : fonctions d’utilité (catalogue → DataFrame) avec accès transactionnel `with engine.begin()` pour garantir la cohérence.

## 5. `core/inventory_service.py`
- **Responsabilité** : orchestrer les ventes (PoS) et les réceptions (factures) → mouvements de stock + tickets.
- **Fonctions** :
  1. `_as_decimal`, `_normalise_quantity` : conversions robustes (Decimal) et vérifient que les quantités sont positives.
  2. `process_sale_transaction` :
     - Agrège les lignes du panier (id, quantité, prix, TVA).
     - Vérifie stocks (SELECT FOR UPDATE sur `produits`).
     - Si les déclencheurs (`trg_update_stock_actuel`) existent, se repose dessus sinon décrémente manuellement `stock_actuel`.
     - Insère des mouvements `SORTIE` dans `mouvements_stock`.
     - Gère les erreurs (produit introuvable, stock insuffisant) et renvoie message/receipt.
  3. `_build_sale_receipt` / `_render_receipt_pdf` : convertissent l’agrégation en ticket PDF (header, lignes, totaux) en générant un flux PDF minimaliste (sans dépendance externe).
  4. `match_invoice_products` : associe une DataFrame de factures avec `produits_barcodes` (code normalisé) pour enrichir les lignes avec `produit_id`, `produit_nom`, `prix_catalogue`, `tva`.
  5. `register_invoice_reception` : prend un DataFrame issu d’une facture (après enrichissement), valide chaque ligne (quantité > 0, produit existant), construit des payloads et insère des mouvements `ENTREE` ou `TRANSFERT`. Retourne un résumé (lignes ingestées, erreurs, quantité totale).
- **Flux** : front PoS → agrégation → `mouvements_stock`. Facture → extraction → matching → `register_invoice_reception`.

## 6. `core/invoice_extractor.py`
- **Responsabilité** : transformer tout type de facture (PDF, texte, DOCX) en lignes structurées (nom, code, quantite, prix, tva).
- **Traits** :
  1. `extract_text_from_file` : détecte l’extension ou le type MIME (PDF, DOCX, TXT) et utilise pypdf, pdfminer ou python-docx. Retourne une chaîne brute.
  2. Normalisation (fonctions `_normalize_*`, `_parse_*`) : retrait des accents, conversion de virgules, suppression des métadonnées (N°GTIN, best_before). Permettent de sortir un dataset propre.
  3. `DEFAULT_TVA_CODE_MAP` : 1:1 avec les codes METRO. `_resolve_tva_value` garantit une TVA ou une valeur par défaut.
  4. `_parse_detail_line`, `_parse_inline_summary` et `_parse_detail_tail_tokens` : identifient les lignes de détail (regie, quantite, prix, tva) à la fin d’une ligne ou après le nom.
  5. `_normalize_barcode` / `_normalize_product_name` : garantissent des codes propres (8-15 chiffres) et un libellé stable.
- **Flux** : fichier PDF → texte brut → parsing heuristique → pondération de TVA → DataFrame renvoyée au service `backend.services.invoices`.

## 7. `core/price_history_service.py`
- **Responsabilité** : historiser les prix d’achat par code-barres/fournisseur, mettre à jour dynamiquement les prix de vente et permettre les filtres analytiques.
- **Fonctions** :
  1. `_ensure_table` : crée `produits_price_history` (tenant_id, code, fournisseur, prix, quantite, date, contexte) et ses indexes.
  2. `record_price_history` : convertit les colonnes (code, prix, quantite, facture_date), insère dans la table via `exec_sql` et déclenche `_update_sale_prices` si des codes sont observés.
  3. `_update_sale_prices` : calcule un prix de vente basé sur `max_price * margin_multiplier * (1 + TVA)` et écrit dans `produits`.
  4. `fetch_price_history` + `fetch_price_history_for_product` : lecture filtrée par produit, code, fournisseur, date; joint le nom via `produits_barcodes`, nettoie `prix_achat`, `quantite`, `facture_date` (pandas) avant de retourner un DataFrame prêt pour le front.
  5. `fetch_latest_price_per_code` : rend la ligne la plus récente par code, utile pour afficher la valeur actuelle du stock dans une vue `CapitalSnapshot`.
- **Flux** : facture importée → `record_price_history` → `produits_price_history` + MAJ `produits` → API `backend/api/prices`.

## 8. `core/product_service.py`
- **Responsabilité** : garantir que les modifications effectuées via le tableau catalogue (Streamlit ou SPA) soient validées et cohérentes, y compris la maintenance des codes-barres.
- **Fonctions** :
  1. `_canonicalize_barcode`, `parse_barcode_input` : nettoient les codes et suppriment les doublons (en comparant en minuscules).
  2. `_coerce_numeric`, `_coerce_text`, `_coerce_bool` : valident les champs modifiables (`prix_vente`, `prix_achat`, `nom`, `categorie`, `actif`), en levant des `ValueError` explicites.
  3. `update_catalog_entry` :
     - Vérifie l’existence du produit dans `produits`.
     - Applique les changements field-by-field.
     - Enrichit/synchronise les codes barres via `products_loader.insert_or_update_barcode`.
     - Retourne un résumé (`fields_updated`, `barcodes` avec `added/skipped/conflicts`).
  4. `delete_product_by_barcode` : supprime soit le code, soit tout le produit si c’était le dernier code (`produits_barcodes` + `produits`).
  5. Définitions des exceptions (`ProductNotFoundError`, `InvalidBarcodeError`) pour que les routers FastAPI répondent correctement.
- **Flux** : front catalogue → champ modifié → validation + update + codes → DB.

## 9. `core/products_loader.py`
- **Responsabilité** : ingestion de données catalogue depuis une facture ou un CSV et initialisation d’un produit dans la base.
- **Phases** :
  1. Normalisation (`_normalize_barcode`, `_normalize_name`, `_clean_codes`).
  2. Détection d’un produit existant (`_find_existing_product_by_barcode`, `_fetch_product_snapshot`, `_fetch_product_by_name`).
  3. Calcul des prix (`_resolve_purchase_price`, `_resolve_sale_price`) qui tiennent compte d’une marge minimale (`DEFAULT_MARGIN_RATE`) et d’un seuil de changement (`PRICE_DELTA_THRESHOLD`).
  4. `insert_or_update_barcode`, `create_initial_stock` : maintiennent `produits_barcodes` et ajoutent un mouvement initial si demandé.
  5. `load_products_from_df` :
     - Range par ligne, détecte catégorie (plusieurs heuristiques comme `ALCOHOL_KEYWORDS`).
     - Crée ou met à jour `produits`, synchronise les codes, enregistre l’historique via `price_history_service`.
     - Retourne un résumé complet (rows_received, created, updated, stock_initialized, barcode summary, errors/rejected rows) utilisé par `backend/services/invoices.import_catalog_from_invoice`.
- **Flux** : dataframe facture → `load_products_from_df` → `produits`/`produits_barcodes` + `mouvements_stock` (optionnel) + réponse de synthèse.

## 10. `core/tenant_service.py`
- **Responsabilité** : initialiser la table `tenants` (utilisée par `backend/dependencies/tenant.py`).
- `ensure_tenants_table()` : crée `tenants` si absent, insère les tenants par défaut (Épicerie, Restaurant) et reconnecte la séquence (setval) pour éviter les conflits.
- **Flux** : exécuté au démarrage via `backend/dependencies/tenant` pour que la résolution du tenant (désormais fournie par les claims JWT) dispose des enregistrements de base.

## 11. `core/user_service.py`
- **Responsabilité** : gérer l’authentification / les rôles (utilisé par l’admin FastAPI).
- **Fonctions** :
  1. `ensure_user_table()` / `bootstrap_default_admin()` : créent la table `app_users` et un admin si la table est vide.
  2. `_hash_password`, `_verify_password`, `generate_secure_password` : hachage pbkdf2_sha256 + génération de passwords complexes.
  3. `get_user_by_login`, `get_user_by_id`, `list_users` : lecture.
  4. `authenticate_user` : login + vérification.
  5. `create_user` : insert avec vérification (longueur, doublons).
  6. `update_user_role`, `_count_admins` : protège contre la suppression du dernier admin.
  7. `reset_user_password` : genère ou fixe un nouveau mot de passe.
- **Flux** : utilisé par `backend.services.admin` pour les endpoints `/admin ... users`, `reset-password`, etc.

## 12. `core/vendor_categories.py`
- **Responsabilité** : charger les règles additionnelles de catégorisation des fournisseurs (utile pour `backend.services.restaurant`).
- **Fonction** : `load_vendor_category_rules` lit `data/vendor_category_mapping.csv` et retourne un tuple de tuples `(aliases, category, types)` qui seront concaténés à la liste `CATEGORY_RULES` dans `restaurant`.
- **Flux** : les règles personnalisées de ton entreprise (L’Incontournable, NOUTAM SAS) peuvent enrichir le parser de relevés bancaires.

---

Chaque section décrit maintenant les fonctions, leur usage et leurs effets sur les tables/flux métier. Si tu veux, je peux maintenant enrichir chaque fichier `/core/*.py` avec des commentaires/docstrings en français reprenant cette analyse. Souhaites-tu que je commence par un fichier en particulier (ex. `inventory_service.py` ou `products_loader.py`) ?
